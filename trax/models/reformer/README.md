## Reformer: The Efficient Transformer

Reformer is a more efficient version of Transformer that uses reversible layers and locality-sensitive hashing.

Read about the details in our [Reformer paper](https://arxiv.org/abs/2001.04451) which was selected for oral presentation at [ICLR 2020](https://iclr.cc/Conferences/2020/).

Generate images with Reformer using [this colab](https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/image_generation.ipynb).

Train Reformer on text of length 0.5M tokens on a single 8GB accelerator code using [this colab](https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/text_generation.ipynb).

Translate from English to German with a reversible encoder-decoder model using [this colab](https://colab.research.google.com/github/google/trax/blob/master/trax/models/reformer/machine_translation.ipynb).
